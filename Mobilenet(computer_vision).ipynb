{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/19A81A0487/Computer-vision/blob/main/Mobilenet(computer_vision).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Packages"
      ],
      "metadata": {
        "id": "IwDkb1qE7aX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF0rH3U_Svca",
        "outputId": "442a010a-4be9-4554-ef45-20075145a8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "H6kNBKN97dea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIyS9mksTWT_"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "model_path = \"/content/drive/MyDrive/mobilenetv2-7 (1).onnx\"\n",
        "\n",
        "model = onnx.load(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Required libraries"
      ],
      "metadata": {
        "id": "zWtW6-FA7fwb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPjalwIEUg5q",
        "outputId": "30de18ab-9aa1-4f7b-ac06-699905cbb629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (24.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 131015 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Video processing frame by frame"
      ],
      "metadata": {
        "id": "N9JJ85na7j1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2VFtARG6xClG",
        "outputId": "b161b13e-37a6-4a00-cbf7-cc02ca7b9542"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pytesseract\n",
        "\n",
        "\n",
        "onnx_model_path = \"/content/drive/MyDrive/mobilenetv2-7 (1).onnx\"\n",
        "ort_session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "def process_output(output, frame):\n",
        "\n",
        "    probabilities = np.exp(output) / np.sum(np.exp(output), axis=1, keepdims=True)\n",
        "\n",
        "    predicted_class = np.argmax(probabilities, axis=1)\n",
        "\n",
        "    label = f\"Predicted class: {predicted_class[0]}\"\n",
        "\n",
        "\n",
        "    processed_frame = frame.copy()\n",
        "    cv2.putText(processed_frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    return processed_frame\n",
        "\n",
        "\n",
        "\n",
        "video_path = \"/content/project_video.com).mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "\n",
        "while cap.isOpened() and frame_count < 50:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Frame {frame_count + 1}: \")\n",
        "\n",
        "    input_size = (224, 224)\n",
        "    preprocessed_frame = cv2.resize(frame, input_size)\n",
        "    preprocessed_frame = np.transpose(preprocessed_frame, (2, 0, 1))\n",
        "    preprocessed_frame = np.expand_dims(preprocessed_frame, axis=0)\n",
        "    preprocessed_frame = preprocessed_frame.astype(np.float32) / 255.0\n",
        "\n",
        "    input_name = ort_session.get_inputs()[0].name\n",
        "    output_name = ort_session.get_outputs()[0].name\n",
        "    outputs = ort_session.run([output_name], {input_name: preprocessed_frame})\n",
        "    processed_frame = process_output(outputs[0], frame)\n",
        "\n",
        "\n",
        "    cv2_imshow(processed_frame)\n",
        "\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "\n",
        "    delay = int(1000 / fps)\n",
        "\n",
        "\n",
        "    if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "print(f\"Frame rate (FPS): {fps}\")\n",
        "print(\"Displayed first 50 frames of the video.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text recognition and time steps"
      ],
      "metadata": {
        "id": "ni6WSRlr7-wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pytesseract\n",
        "\n",
        "\n",
        "onnx_model_path = \"/content/drive/MyDrive/mobilenetv2-7 (1).onnx\"\n",
        "ort_session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "\n",
        "def process_output(output, frame):\n",
        "\n",
        "    probabilities = np.exp(output) / np.sum(np.exp(output), axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "    predicted_class = np.argmax(probabilities, axis=1)\n",
        "\n",
        "\n",
        "    label = f\"Predicted class: {predicted_class[0]}\"\n",
        "\n",
        "\n",
        "    processed_frame = frame.copy()\n",
        "    cv2.putText(processed_frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    return processed_frame\n",
        "\n",
        "def perform_ocr(frame):\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "    _, threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    text = pytesseract.image_to_string(threshold)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "video_path = \"/content/project_video.com).mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "\n",
        "while cap.isOpened() and frame_count < 50:  # Process first 50 frames\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    print(f\"Frame {frame_count + 1}: \")\n",
        "\n",
        "    input_size = (224, 224)\n",
        "    preprocessed_frame = cv2.resize(frame, input_size)\n",
        "    preprocessed_frame = np.transpose(preprocessed_frame, (2, 0, 1))  # Channels first\n",
        "    preprocessed_frame = np.expand_dims(preprocessed_frame, axis=0)  # Add batch dimension\n",
        "    preprocessed_frame = preprocessed_frame.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "    input_name = ort_session.get_inputs()[0].name\n",
        "    output_name = ort_session.get_outputs()[0].name\n",
        "    outputs = ort_session.run([output_name], {input_name: preprocessed_frame})\n",
        "    processed_frame = process_output(outputs[0], frame)\n",
        "\n",
        "\n",
        "    text = perform_ocr(processed_frame)\n",
        "\n",
        "\n",
        "    print(\"Extracted text:\", text)\n",
        "\n",
        "    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "    print(\"Timestamp:\", timestamp)\n",
        "\n",
        "    # Display the processed frame\n",
        "    cv2_imshow(processed_frame)\n",
        "\n",
        "    # Increment frame count\n",
        "    frame_count += 1\n",
        "\n",
        "    # Calculate delay based on FPS (delay in milliseconds)\n",
        "    delay = int(1000 / fps)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Print information about frame rate\n",
        "print(f\"Frame rate (FPS): {fps}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i7mlfIYW7Lbo",
        "outputId": "336224e6-894c-4c5e-d02b-55e5a349ce52"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x8k22hmPkWsI6ILq7EN4AbUA2ed5P-vV",
      "authorship_tag": "ABX9TyM7PxJgSHX45xGBffPyiC5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}